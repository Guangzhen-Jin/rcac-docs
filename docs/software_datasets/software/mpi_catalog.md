# MPI

MPI (Message Passing Interface) implementations provide the foundation for scalable parallel computation across distributed memory nodes. They enable communication, synchronization, and data exchange for multi-node jobs and are optimized for specific interconnects and high-speed interconnects used in HPC.

* [**amduprof**](apps_md/amduprof.md)
* [**cuda**](apps_md/cuda.md)
* [**cudnn**](apps_md/cudnn.md)
* [**impi**](apps_md/impi.md)
* [**intel-oneapi-mpi**](apps_md/intel-oneapi-mpi.md)
* [**mpi4py**](apps_md/mpi4py.md)
* [**mvapich2**](apps_md/mvapich2.md)
* [**nccl**](apps_md/nccl.md)
* [**openmpi**](apps_md/openmpi.md)
* [**py-mpi4py**](apps_md/py-mpi4py.md)
* [**rocm**](apps_md/rocm.md)
* [**ucx**](apps_md/ucx.md)
